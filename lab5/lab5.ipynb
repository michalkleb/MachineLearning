{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytanie danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=pd.read_csv('y_train.csv')\n",
    "y_test=pd.read_csv('y_test.csv')\n",
    "X_train=pd.read_csv('X_train.csv')\n",
    "X_test=pd.read_csv('X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>cabin</th>\n",
       "      <th>CabinReduced</th>\n",
       "      <th>cabin_map</th>\n",
       "      <th>cabin_map_reduced</th>\n",
       "      <th>sex_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>916 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sex cabin CabinReduced  cabin_map  cabin_map_reduced  sex_map\n",
       "0    female   NaN          NaN          6                  5        0\n",
       "1    female   NaN          NaN          6                  5        0\n",
       "2    female   NaN          NaN          6                  5        0\n",
       "3      male   NaN          NaN          6                  5        1\n",
       "4    female   NaN          NaN          6                  5        0\n",
       "..      ...   ...          ...        ...                ...      ...\n",
       "911  female   NaN          NaN          6                  5        0\n",
       "912    male   NaN          NaN          6                  5        1\n",
       "913  female   NaN          NaN          6                  5        0\n",
       "914  female   NaN          NaN          6                  5        0\n",
       "915  female   NaN          NaN          6                  5        0\n",
       "\n",
       "[916 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_train_high=[]\n",
    "roc_test_high=[]\n",
    "roc_train_low=[]\n",
    "roc_test_low=[]\n",
    "\n",
    "def roc_auc_high(y_test,PredTest,y_train,PredTrain):\n",
    "    roc_test_high.append(roc_auc_score(y_test,PredTest))\n",
    "    roc_train_high.append(roc_auc_score(y_train,PredTrain))\n",
    "    print('Dane testowe: {}'.format(roc_train_high[0]))\n",
    "    print('Dane treningowe: {}'.format(roc_test_high[0]))\n",
    "\n",
    "def roc_auc_low(y_test,PredTest,y_train,PredTrain):\n",
    "    roc_test_low.append(roc_auc_score(y_test,PredTest))\n",
    "    roc_train_low.append(roc_auc_score(y_train,PredTrain))\n",
    "    print('Dane testowe: {}'.format(roc_train_low[0]))\n",
    "    print('Dane treningowe: {}'.format(roc_test_low[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Random Forest<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorytm Random Forests** jest to estymator który dopasowuje wiele drzew decyzyjnych do próbek pobranych z badanego zbioru danych.\n",
    "Przy pomocy uśredniania steruje dokładnością predykcji i kontroluje zjawisko over-fittingu. \n",
    "\n",
    "RandomForestClassifier, parametry:\n",
    "- n_estimators - liczba drzew w lesie\n",
    "- random state - kontroluje losowość procesu bootstrapingu "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dane o dużej liczebności cech:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tworzenie modelu\n",
    "RF = RandomForestClassifier(n_estimators=220,random_state=42)\n",
    "\n",
    "#Trenowanie modelu\n",
    "RF.fit(X_train[['sex_map','cabin_map']],np.ravel(y_train))\n",
    "\n",
    "#Predykcja\n",
    "PredTrain = RF.predict_proba(X_train[['sex_map','cabin_map']])\n",
    "PredTest = RF.predict_proba(X_test[['sex_map','cabin_map']].fillna(0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dane testowe: 0.8529126140314685\n",
      "Dane treningowe: 0.7627758420441345\n"
     ]
    }
   ],
   "source": [
    "roc_auc_high(y_test,PredTest[:, 1],y_train,PredTrain[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dane o małej liczebności cech:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trenowanie modelu\n",
    "RF.fit(X_train[['sex_map','cabin_map']],np.ravel(y_train))\n",
    "\n",
    "#Predykcja\n",
    "PredTrain = RF.predict_proba(X_train[['sex_map','cabin_map_reduced']])\n",
    "PredTest = RF.predict_proba(X_test[['sex_map','cabin_map_reduced']].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dane testowe: 0.7334544301822994\n",
      "Dane treningowe: 0.7017449256125214\n"
     ]
    }
   ],
   "source": [
    "roc_auc_low(y_test,PredTest[:, 1],y_train,PredTrain[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W przypadku algorytmu Random Forests dane o dużej liczebności cech uzyskały lepsze wyniki niż dane o małej liczebności, ponieważ przez dużą kardynalnośc cech nastąpiło zjawisko overfittingu -> wynik dla danych treningowych (0,85) zauważalnie lepszy niż dla danych testowych (0,76)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Logistic Regression<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresja logistyczna co do zasady jest podobna do zwykłej regresji liniowej. Podstawową różnicą jest to, że regresja logistyczna nie przewiduje wartości \"y\", tylko przewidywane jest prawdopodobieństwo wystąpienia danej wartości dla zmiennej \"y\". Stosowana jest tutaj funkcja logistyczna postaci: f(x)=1/[1+e^(-Lx)], która wymnożona przez dowolną liczbę rzeczywistą daje wynik w przedziale 0-1, a więc wspomniane wcześniej prawdopodobieństwo. Na koniec, na podstawie prawdopodobieństwa następuje przypisanie danej obserwacji do danej klasy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dane o małej liczebności cech**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tworzenie modelu\n",
    "LR = LogisticRegression(random_state=42)\n",
    "\n",
    "#Trenowanie modelu\n",
    "LR.fit(X_train[['sex_map','cabin_map_reduced']],np.ravel(y_train))\n",
    "\n",
    "#Predykcja\n",
    "PredTrain = LR.predict_proba(X_train[['sex_map','cabin_map_reduced']])\n",
    "PredTest = LR.predict_proba(X_test[['sex_map','cabin_map_reduced']].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dane testowe: 0.7334544301822994\n",
      "Dane treningowe: 0.7017449256125214\n"
     ]
    }
   ],
   "source": [
    "roc_auc_low(y_test,PredTest[:, 1],y_train,PredTrain[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Dane o dużej liczebności cech**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trenowanie modelu\n",
    "LR.fit(X_train[['sex_map','cabin_map']],np.ravel(y_train))\n",
    "\n",
    "#Predykcja\n",
    "PredTrain = LR.predict_proba(X_train[['sex_map','cabin_map']])\n",
    "PredTest = LR.predict_proba(X_test[['sex_map','cabin_map']].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dane testowe: 0.8529126140314685\n",
      "Dane treningowe: 0.7627758420441345\n"
     ]
    }
   ],
   "source": [
    "roc_auc_high(y_test,PredTest[:, 1],y_train,PredTrain[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W przypadku algorytmu LogisticReggresion wyniki dla obu zbiorów, o dużej i małej kardynalności, są dla siebie zbliżone, przy czym dla zbioru o małej liczebności cech różnica pomiędzy zbiorem testowym i treningowym jest minimalna i wynosi jedynie 0.0004."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Gradient Boosting Classifier<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Classifier jest to algorytm skłądający się z N drzew decyzyjnych. W pierwszym kroku następuje predykcja wartości \"y\" zbioru treningowego przy pomocy wartości \"X\" tego zbioru. Następnie obliczana jest różnica pomiędzy predykcją a danymi rzeczywistymi. Różnica ta jest wykorzystana w kolejnym kroku jako zmienna objaśniana, przy czym dodatkowo zostaje przemnożona przez wartości współczynnika \"learning_rate\" i ponownie następuje predykcja itd. Innymi słowy każde kolejne drzewo decyzyjne dąży do zminimalizowania błędów popełnionych przez swojego poprzednika."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dane o dużej liczebności cech**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tworzenie modelu\n",
    "GBC = GradientBoostingClassifier(n_estimators =220, random_state=42)\n",
    "\n",
    "#Trenowanie modelu\n",
    "GBC.fit(X_train[['sex_map','cabin_map']],np.ravel(y_train))\n",
    "\n",
    "#Predykcja\n",
    "PredTrain = GBC.predict_proba(X_train[['sex_map','cabin_map']])\n",
    "PredTest = GBC.predict_proba(X_test[['sex_map','cabin_map']].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dane testowe: 0.8529126140314685\n",
      "Dane treningowe: 0.7627758420441345\n"
     ]
    }
   ],
   "source": [
    "roc_auc_high(y_test,PredTest[:, 1],y_train,PredTrain[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dane o małej liczebości cech**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trenowanie modelu\n",
    "GBC.fit(X_train[['sex_map','cabin_map_reduced']],np.ravel(y_train))\n",
    "\n",
    "#Predykcja\n",
    "PredTrain = GBC.predict_proba(X_train[['sex_map','cabin_map_reduced']])\n",
    "PredTest = GBC.predict_proba(X_test[['sex_map','cabin_map_reduced']].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dane testowe: 0.7334544301822994\n",
      "Dane treningowe: 0.7017449256125214\n"
     ]
    }
   ],
   "source": [
    "roc_auc_low(y_test,PredTest[:, 1],y_train,PredTrain[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla Gradient Boosting Classifier Dane o dużej liczebności cech wskazują na występowanie zjawiska overfittingu (dane treningowe - 0.86, dane testowe - 0.75). Dla danych o małej kardynalności różnica pomiędzy zbiorami wynosi 0.01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Ada Boost Classifier<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ada Boost Clasifier jest podobny do poprzedniego algorytmu. Również wykonuje sekwencję drzew decyzyjnych starająch się minimalizować błędy popełnione przez swojego poprzednika. Jednak różnica polega na sposobie uwzględniania błędów poprzednika. Na podstawie wyliczonego błędu są ustanowione wagi dla zbioru treningowego. Obserwacje które miały największe odchyłki pomiędzy predykcją a rzeczywistą wartością w kolejnym drzewie dostają wyższe wagi niż obserwacje prawdidłowo przewidziane. W ten sposób każde kolejne drzewo coraz lepiej dopasowuje się do danych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dane o dużej liczebności**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tworzenie modelu\n",
    "ADC = AdaBoostClassifier(n_estimators =220, random_state=42)\n",
    "\n",
    "#Trenowanie modelu\n",
    "ADC.fit(X_train[['sex_map','cabin_map']],np.ravel(y_train))\n",
    "\n",
    "#Predykcja\n",
    "PredTrain = ADC.predict_proba(X_train[['sex_map','cabin_map']])\n",
    "PredTest = ADC.predict_proba(X_test[['sex_map','cabin_map']].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dane testowe: 0.8529126140314685\n",
      "Dane treningowe: 0.7627758420441345\n"
     ]
    }
   ],
   "source": [
    "roc_auc_high(y_test,PredTest[:, 1],y_train,PredTrain[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dane o małej liczebnośći**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trenowanie modelu\n",
    "ADC.fit(X_train[['sex_map','cabin_map_reduced']],np.ravel(y_train))\n",
    "\n",
    "#Predykcja\n",
    "PredTrain = ADC.predict_proba(X_train[['sex_map','cabin_map_reduced']])\n",
    "PredTest = ADC.predict_proba(X_test[['sex_map','cabin_map_reduced']].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dane testowe: 0.7334544301822994\n",
      "Dane treningowe: 0.7017449256125214\n"
     ]
    }
   ],
   "source": [
    "roc_auc_low(y_test,PredTest[:, 1],y_train,PredTrain[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla AdaBoost Classifier Dane o dużej liczebności cech wskazują na występowanie zjawiska overfittingu (dane treningowe - 0.83, dane testowe - 0.77). Wynik dla danych o małej kardynalności różnica pomiędzy zbiorami wynosi 0.016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={\n",
    "    'roc_test_low':roc_test_low,\n",
    "    'roc_train_low':roc_train_low,\n",
    "    'roc_test_high':roc_test_high,\n",
    "    'roc_train_high':roc_train_high\n",
    "    }\n",
    "\n",
    "df=pd.DataFrame(data,index=['Random Forest','Logistic Regression','Gradient Boosting Classifier','AdaBoost Classifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_test_low</th>\n",
       "      <th>roc_train_low</th>\n",
       "      <th>diff_low</th>\n",
       "      <th>roc_test_high</th>\n",
       "      <th>roc_train_high</th>\n",
       "      <th>diff_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.7017</td>\n",
       "      <td>0.7335</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.8529</td>\n",
       "      <td>0.0901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.8023</td>\n",
       "      <td>0.8027</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>0.8122</td>\n",
       "      <td>0.0222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Classifier</th>\n",
       "      <td>0.8013</td>\n",
       "      <td>0.8167</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.7562</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>0.1043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost Classifier</th>\n",
       "      <td>0.7999</td>\n",
       "      <td>0.8162</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.7777</td>\n",
       "      <td>0.8331</td>\n",
       "      <td>0.0554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              roc_test_low  roc_train_low  diff_low  \\\n",
       "Random Forest                       0.7017         0.7335    0.0317   \n",
       "Logistic Regression                 0.8023         0.8027    0.0004   \n",
       "Gradient Boosting Classifier        0.8013         0.8167    0.0154   \n",
       "AdaBoost Classifier                 0.7999         0.8162    0.0162   \n",
       "\n",
       "                              roc_test_high  roc_train_high  diff_high  \n",
       "Random Forest                        0.7628          0.8529     0.0901  \n",
       "Logistic Regression                  0.7900          0.8122     0.0222  \n",
       "Gradient Boosting Classifier         0.7562          0.8604     0.1043  \n",
       "AdaBoost Classifier                  0.7777          0.8331     0.0554  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diff_low']=df['roc_train_low']-df['roc_test_low']\n",
    "df['diff_high']=df['roc_train_high']-df['roc_test_high']\n",
    "df=df[['roc_test_low','roc_train_low','diff_low','roc_test_high','roc_train_high','diff_high']]\n",
    "df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Podsumowanie<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla każdego z algorytmów w przypadku danych o dużej liczebności można zauważyc zjawisko overfittingu, najwyraźniej jest ono widoczne dla  Gradient Boost Classifier i Random Forest. Dla danych o niskiej kardynalności różnice pomiędzy zbiorem testowym i treningowym są zauważalnie mniejsze niż w przypadku danych o dużej kardynalności. Moim zdaniem najlepsze rezultaty daje algorytm Logistic Reggresion, ponieważ osiąga najwyższą wartość statystyki roc_auc_score dla danych o małej kardynalności."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> predict vs predict_proba<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>predict()</b>  - zwraca jako wynik dokładne dopasowanie do danej klasy <br>\n",
    "<b>predict_proba()</b> - zwraca jako wynik klasy prawdopodobieństwa, dla każdej potencjalnej klasy jest obliczane prawdopodobieństwo zaliczenia do niej danego elementu"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48bf74fde40f473be21c389489e069b179bcaad57c8bf9bd737d7dbcb7d5233d"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
